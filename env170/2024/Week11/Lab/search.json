[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Week 11 Lab: The Data Goes On and On..",
    "section": "",
    "text": "Introduction\nLast week we learned about vector data as a means to representing discrete spatial data. For example, if you have a polygon showing the boundary of Middlesex County, any point inside that polygon is in the county, and points outside are not. But there is also spatial information that is continuous across space. For example, something like albedo (surface reflectance) will vary continuously across Middlesex County (or anywhere else, for that matter).\nHowever, because these values can be measured at any location, the differences between locations could be infinitely small, making it impossible to capture all the possible variability in a single dataset. A raster instead measures these variables at regular intervals (e.g., every square kilometer), and these values are expressed as a regular grid over an area of interest. This won’t capture all the potential variation, but provides a good approximation of how the values change over a given space.\nIndividual rasters typically store one variable, although these can be combined into a multilayer raster or raster stack. Rasters are used to represent lots of different kinds of environmental data, but have become particularly important as more and more data are accumulated using satellites and other aerial sensing. For example, spectroradiometers mounted on satellites can be used to measure sea surface temperatures at regular intervals, which are then assembled into a raster of values covering the earth’s oceans. Satellite images of the surface of the earth are simply rasters that store color/hue values, which can then be translated to pixels in a digital image.\nIn this lab, we’ll look at working with raster data in R using the terra package. This package was developed to make working with rasters more straightforward, and to better handle the large amounts of data contained in a raster. We’ll also make use of another package called tidyterra, which makes it easier to use terra objects with tidyverse packages like ggplot2. The combination of these two packages will enable us to incorporate raster data into our work in similar ways to other data types we’ve encountered so far.\nTo get started, make sure to download the data from Canvas and load the following packages:\n\n#install.packages(\"terra\")\n#install.packages(\"tidyterra\")\n\nlibrary(tidyverse)\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.4.2\n\nlibrary(terra)\n\nWarning: package 'terra' was built under R version 4.4.2\n\nlibrary(tidyterra)\n\nWarning: package 'tidyterra' was built under R version 4.4.2",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "01_RasterData.html",
    "href": "01_RasterData.html",
    "title": "1  Working with raster data in R",
    "section": "",
    "text": "Warning: package 'terra' was built under R version 4.4.2\n\n\nWarning: package 'tidyterra' was built under R version 4.4.2\n\n\nThe terra package is used to deal with spatial data, but specifically with rasters. A major advantage of this package is its ability to work with large datasets. Rasters can include a lot of data; for example, a single coverage of a 5 km2 area at a 1m resolution contains 25 million grid cells. The terra package makes handling data at these volumes more manageable.\n\nWhat is raster data?\nA raster is closely related to another object called a matrix, which is a rectangular array of numbers. They are used in mathematics for mapping relationships between linear systems, and serve a number of functions in computer science. For our purposes, we can think of them like a table without headers, where the column and row numbers are equivalent to x position and y position at a given spatial interval (e.g., a column/row for every 50 m easting/northing or every 0.1° longitude/latitude). Every cell or pixel in that headerless table contains a value that is a measurement of some variable at those x-y coordinates (e.g., temperature, elevation, etc.)\n\n\n\ndocs.qgis.org\n\n\nTo show how this works, we’re going to dip back into Base R for a moment. First, let’s use rnorm to generate a set of 10,000 random values, normally distributed around a mean of 0 and with a standard deviation of 1.\n\n#Generate 10000 random values \nrandomValues&lt;-rnorm(10000,0,1)\nrandomValues[1:10]\n\n [1]  1.0348366  0.6522640 -1.4540501 -2.0085542  0.4887037 -1.4854700\n [7]  0.7758884 -0.7053838  1.0892177 -0.8190491\n\n\nHere, we’re using square brackets to look at the first ten of these random values. Now let’s say we want to take this and turn it into a matrix with 100 rows and 100 columns. We can use our randomValues as an argument in the matrix function, along with arguments for the number of rows (nrow) and columns (ncol):\n\n#Generate 10000 random values in a 10x10 matrix\nrandomMatrix&lt;-matrix(randomValues,nrow=100,ncol=100)\n#Show first ten rows of first five columns\nrandomMatrix[1:10,1:5]\n\n            [,1]       [,2]          [,3]        [,4]       [,5]\n [1,]  1.0348366  0.5905468  0.1299541283 -0.04448339  1.4289052\n [2,]  0.6522640  0.5275579  0.6877795489  0.72987128  0.6440253\n [3,] -1.4540501 -2.1890450  0.0002318932  0.03166149  1.1696872\n [4,] -2.0085542 -1.9382868  1.1633936558 -0.25911973  0.6870340\n [5,]  0.4887037  1.3665376 -0.4592813435 -1.23227965 -0.1163580\n [6,] -1.4854700  0.2924812  0.8792707122  1.56490429 -0.3817497\n [7,]  0.7758884  0.5098766  1.9091407424 -1.08489408  0.5957195\n [8,] -0.7053838  2.2968982 -0.3270155508 -1.04935891  2.3419402\n [9,]  1.0892177  1.0718190 -0.1938226216  2.57012379 -1.0769093\n[10,] -0.8190491  1.9115245 -0.7221258214  0.06197989  1.1506261\n\n\nThis gives us a sense of what the matrix looks like: the far left shows row numbers, while the top has column numbers, both in square brackets. The numbers in between are the random values we generated, but now organized in a 100 x 100 matrix. We can see how many rows and columns are in the matrix using the dim function:\n\ndim(randomMatrix)\n\n[1] 100 100\n\n\nOK, now that we have data, we want to turn it into a raster.\n\n#Turn matrix into SpatRaster object\nrandomRaster&lt;-rast(randomMatrix)\nrandomRaster\n\nclass       : SpatRaster \ndimensions  : 100, 100, 1  (nrow, ncol, nlyr)\nresolution  : 1, 1  (x, y)\nextent      : 0, 100, 0, 100  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nname        :     lyr.1 \nmin value   : -4.298846 \nmax value   :  3.781577 \n\n\nThis gives us some information about the spatRaster object, including:\n\ndimensions (100 rows, 100 columns, 1 layer)\nresolution (the size of a single cell, here 1x1)\nextent (like a bounding box, giving the maximum and minimum x and y values)\ncoord. ref (CRS, not yet defined here)\nname of the variable (lyr.1 by default since we didn’t specify), and the minimum and maximum values.\n\nOne of these properties worth mentioning is resolution, which is the size of a grid cell. Grids with smaller cells are better resolved, but this comes at a computational cost of recording, storing, and manipulating much more data. Anyone dealing with raster data must therefore make choices about what resolution is necessary for their purposes, and anyone later using that data must account for the resolution of the data.\nIf we want to visualize these using ggplot2, we need an appropriate geom. The geom_spatraster function comes from tidyterra, which is built to simplify interactionse between terra and tidyverse:\n\nggplot()+\n  geom_spatraster(data=randomRaster)\n\n\n\n\n\n\n\n\nThe syntax is very similar to what we saw with geom_sf, but this visualization shows what raster data looks like: gridded cells where the x and y position of each cell is determined by its column and row number, and its color is based on the value assigned at that position. Of course, being randomly generated data, it doesn’t show a pattern.\nRight now, our random data are distributed in an abstract 100x100 coordinate space. If we want to make our data useful for understanding the world, we need to use coordinates based on a reference system. Like sf objects, spatRaster objects also need a CRS to do this.\nThe crs function lets us do this; however, it requires a character value rather than a number. We can still use the EPSG codes we learned about last week, but this just needs to be preceded by epsg: and put into quotation marks, like so:\n\ncrs(randomRaster) &lt;- \"epsg:4326\" \nrandomRaster\n\nclass       : SpatRaster \ndimensions  : 100, 100, 1  (nrow, ncol, nlyr)\nresolution  : 1, 1  (x, y)\nextent      : 0, 100, 0, 100  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nname        :     lyr.1 \nmin value   : -4.298846 \nmax value   :  3.781577 \n\n\nNow, you might be rightly asking here “Why does crs under terra require it to be \"epsg:4326\" while st_crs from the sf package only needs it to be 4326?!” By now, you’ve seen many differences in the way that functions/arguments are structured, and this lack of uniformity can be frustrating to new users.\nThe answer to this question lies in the way that R packages are developed. While Base R is maintained by a core group of developers, the software is open-source, and packages are usually built by other individuals or groups who want to use R for a specific application (such as spatial data analysis). They create their own functions in R to suit these needs, and may release them to the wider public, which is the case with both sf and terra.\nThis process of public development allows R to grow organically to serve an ever expanding base of users and work for a diversity of applications. But it also means that while packages have to adhere to the rules of the R programming language, other conventions, such as what kinds of inputs an argument requires, may vary from package to package. If you’re ever unsure about what the arguments need to look like, the R help can provide you with more information, particularly the examples at the bottom of each help page.\nComing back to our random raster with a CRS, when we plot the data, the coordinates (position in the matrix) are given as degrees longitude and latitude:\n\nggplot()+\n  geom_spatraster(data=randomRaster)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it yourself!\n\n\n\nTry and run through the example above again, but when you create the randomValues vector, use the sort function to sort the values from least to greatest. What do you think will happen?\n\n\nYou might have noticed that our raster includes latitude values that go above 90°N. When we first defined the raster, we set it up to have a resolution of 100 x 100 cells, but we didn’t define the units. Then later, when we then gave it a CRS, we didn’t bother to check whether all of our longitude/latitude values make sense.\nIf we know, for example, that the coordinate space only goes up to 90°N, we can set this extent using the ext function.\n\next(randomRaster) &lt;- c(0, 100, 0, 90)\nrandomRaster\n\nclass       : SpatRaster \ndimensions  : 100, 100, 1  (nrow, ncol, nlyr)\nresolution  : 1, 0.9  (x, y)\nextent      : 0, 100, 0, 90  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nname        :     lyr.1 \nmin value   : -4.298846 \nmax value   :  3.781577 \n\n\nThis is telling R: the extent of the randomRaster object within the WGS 84 coordinate reference system is 0 - 100 along the x-axis (longitude), and 0 - 90 along the y-axis (latitude). This reconfigures the data to fit that space, not by deleting the data outside that extent, but changing the resolution of the y-axis. You can see this now in the resolution section of the information above, which shows that grid cells are now 1º wide on x axis (longitude), and 0.9º tall on the y-axis. In other words, our grid cells are no longer squares, but slightly squat rectangles.\nNow when we plot the, we can see that it now fits within that space:\n\nggplot()+\n  geom_spatraster(data=randomRaster)\n\n\n\n\n\n\n\n\nIn this case, since the data are invented, it isn’t a big deal to make this kind of change. But whenever we mess around with the extents or resolutions, we need to be aware of what our CRS is, and how the data are recorded, to make sure that the data remain faithful to the phenomena they represent.\n\n\nMultirasters\nA single raster is really useful if you’re looking at a single variable from a given snapshot in time (average temperature for a given day), or at some variable that doesn’t tend to change much over time (like elevation). For data that varies over time, we can use structures called multirasters: these are raster datasets with multiple layers. These can be useful for storing different kinds of data within the same spatRaster object, or storing raster data that’s been collected over time.\nTo make one of these from scaratch, we’ll generate three random rasters, and then combine them just as we would a vector:\n\n#Generate 100 random values in a 10x10 matrix\nrandomValues1&lt;-matrix(runif(100,0,1),nrow=10,ncol=10)\nrandomValues2&lt;-matrix(runif(100,0,1),nrow=10,ncol=10)\nrandomValues3&lt;-matrix(runif(100,0,1),nrow=10,ncol=10)\n\nraster1&lt;-rast(randomValues1)\nraster2&lt;-rast(randomValues2)\nraster3&lt;-rast(randomValues3)\n\nmultiRaster&lt;-c(raster1,raster2,raster3)\n\nWe can see how many layers are in this dataset using the nlyr function:\n\nnlyr(multiRaster)\n\n[1] 3\n\n\nWhen we look at this data, though, each raster in the set has the same default name:\n\nmultiRaster\n\nclass       : SpatRaster \ndimensions  : 10, 10, 3  (nrow, ncol, nlyr)\nresolution  : 1, 1  (x, y)\nextent      : 0, 10, 0, 10  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nnames       :      lyr.1,       lyr.1,      lyr.1 \nmin values  : 0.01464499, 0.007207026, 0.01490451 \nmax values  : 0.99317883, 0.989193002, 0.99908353 \n\n\nWe can access layer names using the names function, and assign a vector of layer names as character values:\n\nnames(multiRaster)&lt;-c(\"raster1\",\"raster2\",\"raster3\")\nmultiRaster\n\nclass       : SpatRaster \ndimensions  : 10, 10, 3  (nrow, ncol, nlyr)\nresolution  : 1, 1  (x, y)\nextent      : 0, 10, 0, 10  (xmin, xmax, ymin, ymax)\ncoord. ref. :  \nsource(s)   : memory\nnames       :    raster1,     raster2,    raster3 \nmin values  : 0.01464499, 0.007207026, 0.01490451 \nmax values  : 0.99317883, 0.989193002, 0.99908353 \n\n\nVisualizing all the layers here requires us to use the facet_wrap function, and the argument we use is ~lyr. This is accessing the lyr (layer) property of the spatRaster object.\n\nggplot() +\n  geom_spatraster(data = multiRaster) +\n  facet_wrap(~lyr)\n\n\n\n\n\n\n\n\nIf you want to extract a single raster from this set, you can use the $ operator:\n\nfirstRaster&lt;-multiRaster$raster1\n\nggplot() +\n  geom_spatraster(data = firstRaster)\n\n\n\n\n\n\n\n\nOr you can you use square brackets:\n\nsecondRaster&lt;-multiRaster['raster2']\n\nggplot() +\n  geom_spatraster(data = secondRaster)\n\n\n\n\n\n\n\n\n\n\nReading in raster data\nWhile building rasters from scratch helps us understand the object’s properties, most uses in data science will involve loading in raster data from a file. Raster data can be read into R from a number of different file formats (check here for a full list), but generally speaking most common image formats (e.g., .jpg, .bmp, .img) can be read as rasters. One of the most common formats used to store raster data is a GeoTIFF (.tif) file.\n\nturkanaDEM&lt;-rast(\"data/turkanaDEM.tif\")\nturkanaDEM\n\nclass       : SpatRaster \ndimensions  : 720, 720, 1  (nrow, ncol, nlyr)\nresolution  : 0.004166667, 0.004166667  (x, y)\nextent      : 35, 38, 2, 5  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : turkanaDEM.tif \nname        : turkanaDEM \n\n\nThis is surface elevation data, both bathymetric and topographic, from the GEBCO Gridded Bathymetry dataset hosted by the British Oceanographic Data Centre. It is centered on the area on the eastern shore of Lake Turkana in Kenya. Like the data we created, we can see the properties of this dataset like its extent and resolution. Plotting is also the same as above using geom_spatraster:\n\nggplot() +\n  geom_spatraster(data=turkanaDEM)\n\n\n\n\n\n\n\n\nHere, we can see the elevation values mapped out, with a few peaks extending over 2000 meters a.s.l.\nMultilayer rasters can also be stored as GeoTIFFs, and satellite images are often stored this way and include multiple layers for different color bands. Another common standard used in the earth sciences for multilayer rasters is a NetCDF (.nc) file. Here, we’ll load in a NetCDF of monthly rainfall values for the Lake Turkana area, obtained from the TerraClimate dataset (no relation to the terra package) from the Climatology Lab at UC Merced.\n\nturkanaRain&lt;-rast(\"data/turkanaRain.nc\")\nturkanaRain\n\nclass       : SpatRaster \ndimensions  : 72, 72, 756  (nrow, ncol, nlyr)\nresolution  : 0.04166667, 0.04166667  (x, y)\nextent      : 35, 38, 2, 5  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : turkanaRain.nc \nnames       : turka~ain_1, turka~ain_2, turka~ain_3, turka~ain_4, turka~ain_5, turka~ain_6, ... \n\n\nAnd we can check the number of layers:\n\nnlyr(turkanaRain)\n\n[1] 756\n\n\nMultilayer rasters can also be subset using the select function (thanks to tidyterra!):\n\nturkanaRain4&lt;-select(turkanaRain,c('turkanaRain_1':'turkanaRain_4'))\nturkanaRain4\n\nclass       : SpatRaster \ndimensions  : 72, 72, 4  (nrow, ncol, nlyr)\nresolution  : 0.04166667, 0.04166667  (x, y)\nextent      : 35, 38, 2, 5  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : turkanaRain.nc \nnames       : turkanaRain_1, turkanaRain_2, turkanaRain_3, turkanaRain_4",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Working with raster data in R</span>"
    ]
  },
  {
    "objectID": "02_VisualizingRasters.html",
    "href": "02_VisualizingRasters.html",
    "title": "Week 11 Lab: The Data Goes On and On..",
    "section": "",
    "text": "Warning: package 'terra' was built under R version 4.4.2\n\n\nWarning: package 'tidyterra' was built under R version 4.4.2\n\n\nFor the most part, visualizing raster data follows the same rules as other continuous datasets. Here, we’ll use GEBCO data centered around Cebu City in the Phillippines.\n\ncebuDEM&lt;-rast(\"data/cebu_DEM.tif\")\n\nRaster data behaves similarly to the 2D bin or heatmap objects we’ve seen before, the primary aesthetic attribute to be used here is fill color. Therefore, all of the scale_fill_* functions apply here. For example, scale_fill_gradient will plot between low and high values:\n\nggplot() +\n  geom_spatraster(data=cebuDEM) +\n  scale_fill_gradient(low=\"blue\",high=\"red\") +\n  theme_minimal() +\n  labs(fill=\"Elevation (m)\")\n\n\n\n\n\n\n\n\nThis isn’t particularly revealing. Alternatively, we can use scale_fill_gradient2 to use divergent colors, here using a midpoint of 0m to split the gradient at sea level:\n\nggplot() +\n  geom_spatraster(data=cebuDEM) +\nscale_fill_gradient2(low=\"red\",mid=\"yellow\",high=\"darkgreen\",midpoint=0)  +\n  theme_minimal() +\n  labs(fill=\"Elevation (m)\")\n\n\n\n\n\n\n\n\nThat’s a little clearer. Other palettes work here as well. Here’s a how it looks with viridis, using the magma palette:\n\nggplot() +\n  geom_spatraster(data=cebuDEM) +\nscale_fill_viridis_c(option=\"magma\")  +\n  theme_minimal() +\n  labs(fill=\"Elevation (m)\")\n\n\n\n\n\n\n\n\nBy the way, if we want to generate a summary statistic about the cell values in our raster, we can access these using the values function:\n\nmax(values(cebuDEM))\n\n[1] 925\n\nmin(values(cebuDEM))\n\n[1] -1932\n\n\nThis can be useful for setting\n\nelevations&lt;-values(cebuDEM)\nggplot(data=elevations,aes(cebu_DEM))+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWith elevation or other continuous data, we may want to apply colors that correspond to particular intervals. One way to do this us using the rescale from the scales package:\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:terra':\n\n    rescale\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nmn&lt;-min(values(cebuDEM))\nmx&lt;-max(values(cebuDEM))\nrescaledElev&lt;-rescale(c(mn,-1000,-500,0,500,mx),to=c(0,1))\n\nHere what we’ve done is first create variables storing the minimum and maximum values from the raster. Then we used rescale to create a vector of values between that minimum and maximum, but scaled between 0 and 1. We can use these to control the look of the plot plot with scale_fill_gradientn:\n\nggplot() +\n  geom_spatraster(data=cebuDEM) +\nscale_fill_gradientn(colors=c(\"darkblue\",\"blue\",\"skyblue\",\"darkgreen\",\"lightgreen\"),values=rescaledElev)\n\n\n\n\n\n\n\n\nThis looks OK, but since maps often have distinct color boundaries between water and land, we might want to indicate those colors with blue. s, so we can set a hard boundary by adding two values after the minimum: -1 and 1\n\nrescaledElev&lt;-rescale(c(mn,-1000,-500,-1,0,1,500,mx),to=c(0,1))\n\nNow when we run the ggplot, we can add two new colors: dark blue and blue, so our values will scale up to blue shades only through to 361\n\nggplot() +\n  geom_spatraster(data=cebuDEM) +\nscale_fill_gradientn(colors=c(\"darkblue\",\"blue\",\"skyblue\",\"darkgreen\",\"lightgreen\"),values=rescaledElev)+\n  theme_minimal() +\n  labs(fill=\"Elevation (m)\")\n\n\n\n\n\n\n\n\nAt this point, we could continue to modify the colors and rescaled intervals until we get the precise look we want, but it looks much more like a map of the terrain and waterways around Cebu City. The same principles work for multilayer rasters. For example, we can apply these individually:\n\nggplot() +\n  geom_spatraster(data=turkanaRain$turkanaRain_4) +\nscale_fill_distiller(palette = \"RdBu\",direction=1) +\n  theme_minimal() +\n  labs(fill=\"Precipitation \\n(mm)\")\n\n\n\n\n\n\n\n\nOr we can plot values across multiple rasters using facet_wrap:\n\nggplot() +\n  geom_spatraster(data=turkanaRain4) +\n  facet_wrap(~lyr) +\nscale_fill_distiller(palette = \"RdBu\",direction=1,na.value=\"black\")+\n  theme_minimal() +\n  labs(fill=\"Precipitation \\n(mm)\")\n\n\n\n\n\n\n\n\nNote that bit at the end where it reads na.values=\"black\". This can be used in any scale_color_* or scale_fill_* function to account data points that have NA values. It’s important to make sure that your NA values are colored using a value that does not appear in your scale. However, here we have no NA values, so there are no black cells.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>02_VisualizingRasters.html</span>"
    ]
  },
  {
    "objectID": "03_ManipulatingRasters.html",
    "href": "03_ManipulatingRasters.html",
    "title": "3  Manipulating rasters",
    "section": "",
    "text": "Raster algebra\nRaster algebra is the task of modifying values . You could think of this as akin to the mutate function. For example, let’s say we wanted to convert our elevation data, currently in feet above sea level, to meters. The conversion from meters to feet is:\n\\[ f \\times 3.28 \\]\nTo apply this across our raster, we simply multiply it by 3.28.\n#convert m to feet\nturkanaDEM_ft&lt;-turkanaDEM*3.28\nggplot()+\n  geom_spatraster(data=turkanaDEM_ft)\nThe surface of Lake Turkana is about 1200 feet above sea level. We could just get those cells above the lake level using the same kind of algebra.\nturkanaLand&lt;-turkanaDEM_ft&gt;1200\nggplot()+\n  geom_spatraster(data=turkanaLand)\nHere, the raster returned to us is a Boolean (true/false) raster.\nWe can also use raster algebra on more than one raster. For example, let’s say we wanted to sum the rainfall for the first four months in the rainfall data. We can use our turkanaRain4 data from earlier and sum the values in the four layers:\n#convert m to feet\nturkanaRain_JanApr&lt;-sum(turkanaRain4)\nturkanaRain_JanApr\n\nclass       : SpatRaster \ndimensions  : 72, 72, 1  (nrow, ncol, nlyr)\nresolution  : 0.04166667, 0.04166667  (x, y)\nextent      : 35, 38, 2, 5  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource(s)   : memory\nname        :   sum \nmin value   :  97.1 \nmax value   : 414.9\nAs you can see, this creates a new raster based on the sum of the four layers in the dataset.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulating rasters</span>"
    ]
  },
  {
    "objectID": "03_ManipulatingRasters.html#raster-algebra",
    "href": "03_ManipulatingRasters.html#raster-algebra",
    "title": "3  Manipulating rasters",
    "section": "",
    "text": "Try it yourself!\n\n\n\nTry seeing if you can take the mean of the first twelve layers of the rainfall data and convert it into inches.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Manipulating rasters</span>"
    ]
  },
  {
    "objectID": "LabExercise9.html",
    "href": "LabExercise9.html",
    "title": "4  Week 11 Lab Exercise",
    "section": "",
    "text": "In this exercise, you’ll be using the terra and tidyterra packages to transform a raster dataset, sample it, and then visualize it. The data you’ll be using is satellite imagery from an area near Lake Turkana in Kenya (eastTurkana.tif). These data contain four layers: three values that are in the visual spectrum (red, green, and blue), and then one in near-infrared (nir).\n\nThese sensor reflectance values are highly exaggerated so that they can store precise numbers as integers rather than floating point (double) numbers. To convert them to reasonable reflectance values, we need to divide them by 10000.\nCalculate the Normalized Difference Vegetation Index: a measure of vegetation greenness that is used as an indicator of vegetation cover. The equation for this is NDVI = (NIR - RED)/(NIR + RED)\n\nNDVI values below 1 are indicative of cloud cover or water, while values below 0.1 are usually indicative bare earth. When plotting, visualize these using a palette that emphasizes a different values that are greater or less than 0.1.\nInclude your code in a Quarto document with appropriate headings and descriptive text. Grading criteria are available on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 11 Lab Exercise</span>"
    ]
  }
]