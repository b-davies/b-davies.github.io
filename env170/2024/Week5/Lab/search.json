[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exploratory Data Analysis in R",
    "section": "",
    "text": "Introduction\nLast week we looked at visualizing data, emphasizing how visualization can be used to reveal patterns that are not obvious in raw data. But how do we begin to look at data? What kinds of things should we be looking for? And how does this help guide our ability to analyze and tell stories with data?\nThis week we’ll build on our visualization skills by employing them in Exploratory Data Analysis. EDA is one of the first steps taken in any data science project. It is used to reveal patterns and problems in data, and help to solidify the research questions, analytical methods, and visualization techniques you will use. But EDA is less a formal set of procedures and more like a dialogue you have with the data; the actual procedures you undertake will depend on what you are looking for and what you find as you go. In this lab, you will learn about:\n\nCommon data types, their properties, and how they are visualized\nWhat kinds of descriptive patterning to look for when evaluating data visually\nHow to manage true and anomalous outliers\n\nFor this lab, we’ll be looking at a number of different datasets. You will need to download the Week5Data.zip folder, unzip it, and then save the contents to the appropriate place in your file system. We’ll also be using the following packages, which may need to be installed for your use here:\n\n#install.packages(\"datasets\")\n#install.packages(\"modeldata\")",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "01_WhyDoEDA.html",
    "href": "01_WhyDoEDA.html",
    "title": "1  Introducing Exploratory Data Analysis",
    "section": "",
    "text": "One of the main reasons data science exists is that there is an enormous amount of data available for study that have already been collected or are actively being generated. Data collected by researchers, governments, corporations, and even the public at large are growing every day, and this offers tremendous opportunities to combine, remix, and re-use data to gain insights about the world around us. But this comes with a caveat: secondary data users have no control over how the data are generated, nor will they necessarily get a complete account of how it was generated.\nBefore putting a dataset to a secondary use, you’ll need get familiar with it. In particular, you’ll want to know:\n\nAre these data useful for a given purpose?\nIs the quality of these data sufficient to use?\nDo these data show potentially meaningful patterning?\n\nExploratory Data Analysis is an approach to evaluate the composition and structure within a dataset prior to formal modeling or hypothesis testing. In this process, we use visualizations, transformations, and statistical summaries to systematically look at data and identify where interesting or relevant patterning lies.\nThere is no definitive set of rules for how to conduct this kind of analysis. Instead, there are a wide array of guidelines and techniques you might apply depending on what kind of data you have and what aspects of the data you are interested in. In the rest of this section, we’ll look at what kinds of data we might expect to encounter, and then look at them individually.\n\nKnowing Your Data\nA first step towards exploring data is to understand what kind of data you’re dealing with. As we discussed in Week 4, different kinds of data will be better represented by different kinds of visualizations. But they will also be amenable to different kinds of analyses, and have different peculiarities.\nHave a look at the first few rows of the olympics dataset:\n\nolympics&lt;-read_csv(\"data/olympics.csv\")\n\nRows: 39783 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): Name, Sex, NOC, Season, Sport, Medal\ndbl (4): Age, Height, Weight, Year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nolympics\n\n# A tibble: 39,783 × 10\n   Name                 Sex     Age Height Weight NOC    Year Season Sport Medal\n   &lt;chr&gt;                &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;\n 1 Edgar Lindenau Aabye M        34     NA     NA DEN    1900 Summer Tug-… Gold \n 2 Arvo Ossian Aaltonen M        30     NA     NA FIN    1920 Summer Swim… Bron…\n 3 Arvo Ossian Aaltonen M        30     NA     NA FIN    1920 Summer Swim… Bron…\n 4 Juhamatti Tapio Aal… M        28    184     85 FIN    2014 Winter Ice … Bron…\n 5 Paavo Johannes Aalt… M        28    175     64 FIN    1948 Summer Gymn… Bron…\n 6 Paavo Johannes Aalt… M        28    175     64 FIN    1948 Summer Gymn… Gold \n 7 Paavo Johannes Aalt… M        28    175     64 FIN    1948 Summer Gymn… Gold \n 8 Paavo Johannes Aalt… M        28    175     64 FIN    1948 Summer Gymn… Gold \n 9 Paavo Johannes Aalt… M        32    175     64 FIN    1952 Summer Gymn… Bron…\n10 Kjetil Andr Aamodt   M        20    176     85 NOR    1992 Winter Alpi… Gold \n# ℹ 39,773 more rows\n\n\nThis dataset includes each Olympic medallist from 1896 to the 2016 summer games. Just looking at the preview of the tibble, we can see a lot of different kinds of data here. Some of it is numbers, some of it is character values. In previous sessions, we’ve talked about these as numerical and categorical data. But even these categories are broad: there are different kinds of numerical data here, and different kinds of categories. A more detailed way to distinguish these kinds of data is in terms of level of measurement, which are nominal, ordinal, interval, and ratio. We’ll go through each one of these individually so we know what we’re looking at.\n\nNominal data\nNominal data is data without a meaningful distance or order between values. In other contexts we’ve referred to this as categorical data, which means that each distinct value is used to assign the observation to a given group or category. For example, if the dataset were ice cream cones sold at an ice cream parlor during a given week, the ice cream cones might be grouped by flavor (e.g., chocolate, vanilla, cookies & cream, etc.). The collection of flavors are categories, or names, making this a nominal variable.\nThis kind of data can also be thought of as discrete, because the data exist within a set of values that have a non-infinite gap between them. This is different from continuous, or measured, data, which we’ll talk about in a moment.\nIn the olympics dataset, there are several columns containing nominal data. These include:\n\nName\nSex\nNOC, which stands for National Olympic Committee\n\nIf we want to look at this nominal data, we have a few options, but our most trusted tool is the bar plot, which will show us the counts of each category.\n\nggplot(olympics,aes(x=Sex)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nBy adding another aesthetic (like fill color), we can make a stacked bar to look at more than one nominal variable.\n\nggplot(olympics,aes(x=Sex,fill=Season)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThis is displaying the data in terms of two nominal variables: sex of medalist, and the season of their competition. Already, we’re starting to see patterns. There are far more male than female medalists in this dataset, and overall there are fewer Winter than Summer medals. Why might this be? Think about this before moving on.\nSeeing patterns can put us in a mindset for finding an explanation. A quick look at the history of the games can get us the information we need. For the first pattern, there were fewer events open to female participants in the early Olympic games relative to today:\nFind more statistics at  Statista\nFor the second, the Winter Olympics has not been held as long as the Summer Games, and has historically has fewer medalling events overall.\n\n\nOrdinal data\nLike nominal data, ordinal data is categorical, but unlike nominal data it has a logical order. You might imagine someone ranking their favorite desserts, or giving their satisfaction on a scale of 1 to 5. This ordering is a usable source of information for analytic purposes.\nIn our Olympics dataset, there is only one ordinal variable, and that’s the Medal column, whereby the medal is indicative of the rank of the athlete in the competition. The ranking, of course, is Gold &gt; Silver &gt; Bronze.\nAgain, bar charts are going to be a good choice for this. Let’s view the numbers of each medal category brought home by Denmark:\n\n#subset to just Denmark's medals\nolympicsDEN&lt;-olympics[olympics$NOC==\"DEN\",]\n\n#plot the data\nggplot(olympicsDEN,aes(x=Medal)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThere’s an issue with this plot, though: we usually wouldn’t want to treat ranked data out of order. We’ve seen one way to deal with this before, using the fct_infreq function:\n\nggplot(olympicsDEN,aes(x=fct_infreq(Medal))) +\n  geom_bar()\n\n\n\n\n\n\n\n\nNow the medals are re-ordered based on their frequency, but this order doesn’t make sense with respect to the Gold &gt; Silver &gt; Bronze ordering inherent in Olympic medals. To deal with this, we can use the fct_relevel function.\n\nggplot(olympicsDEN,aes(x=fct_relevel(Medal,\"Gold\",\"Silver\",\"Bronze\"))) +\n  geom_bar()\n\n\n\n\n\n\n\n\nHere, the function takes as an argument the variable name, followed by the list of values in the correct order. Now our medals are listed in the correct order, but of course this has messed with our x-axis label. Using proper labels is important when you’re using graphics to communicate with someone else, but isn’t necessary when you’re just looking at data by yourself as long as you know what the variables are. But if we wanted to change the labels, we can add a labs layer:\n\nggplot(olympicsDEN,aes(x=fct_relevel(Medal,\"Gold\",\"Silver\",\"Bronze\"))) +\n  geom_bar() +\n  labs(x=\"Medal\",y=\"Count\",title=\"Denmark's Olympic Medals\")\n\n\n\n\n\n\n\n\nBeyond visualization, there are certain statistical tests designed for dealing with ranked data. We’ll touch on these in a later lecture.\n\n\nInterval and Ratio\nInterval and ratio data are examples of numerical data. This means that the distances between values have meaning, so they can be used in arithmetic operations (e.g., you can add them, subtract them, multiply them, etc.). If the values are integers only (for example, number of offspring in a litter), then they are discrete. If they are measuring something where the space between whole values is infinitely divisible (e.g., 5.4, 5.41, 5.413, 5.4138, etc.), then they are continuous.\nInterval data are numerical data with no true zero value; in other words, zero does not indicate absence. Usually, the presence (or possibility) of negative values is a dead giveaway that you’re dealing with interval data. We don’t have any interval data in this Olympics dataset. However, something that would be interval data would be latitude and longitude coordinates of the host cities:\n\noCities&lt;-read_csv(\"data/olympicCities.csv\")\n\nRows: 43 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, Country, Season\ndbl (3): Times_Hosted, Latitude, Longitude\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\noCities\n\n# A tibble: 43 × 6\n   City        Country       Times_Hosted Latitude Longitude Season\n   &lt;chr&gt;       &lt;chr&gt;                &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; \n 1 Athens      Greece                   2     38.0    23.7   S     \n 2 Paris       France                   2     48.9     2.35  S     \n 3 St. Louis   United States            1     38.6   -90.2   S     \n 4 London      England                  3     51.5    -0.123 S     \n 5 Stockholm   Sweden                   1     59.3    18.1   S     \n 6 Antwerp     Belgium                  1     51.2     4.4   S     \n 7 Amsterdam   Netherlands              1     52.4     4.9   S     \n 8 Los Angeles United States            2     34.0  -118.    S     \n 9 Berlin      Germany                  1     52.5    13.4   S     \n10 Helsinki    Finland                  1     60.2    24.9   S     \n# ℹ 33 more rows\n\n\nWhy is this interval data? A value of 0 latitude doesn’t indicate an absence of latitude but instead indicates that you are on the equator, and negative values indicate that you are south of it. Ratio data, on the other hand, is numerical data with a true zero value. Our olympics data has several examples of this:\n\nHeight\nWeight\nAge\n\nInterestingly, these are given as integer values, which are discrete. However, any of these could have given as continuous values, such as 175.34 cm. But it is often convention, particularly with age, to use integer values.\nWhen we’re looking at interval and ratio data, the most common way to represent this kind of data visually is a histogram.\n\nggplot(olympics,aes(x=Weight)) +\n  geom_histogram(bins=20) \n\nWarning: Removed 9327 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nDid you see the warning? It was probably something like this:\nWarning: Removed 9327 rows containing non-finite outside the scale range (stat_bin()).\nWhen R says rows have been removed, that usually means that there was something in those rows that couldn’t be plotted. In this case, there are a number of data that are NA, meaning that data was not recorded or is not available.\nYou might be (rightly) asking at this stage in the course why we regularly use histograms. This is something we’ll go over in the next section.\n\n\n\n\n\n\nTry it yourself!\n\n\n\nWithout looking at the oCities data as a table, see if you can find a quick way to visualize how many different cities in the southern hemisphere have hosted the Olympics.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducing Exploratory Data Analysis</span>"
    ]
  },
  {
    "objectID": "02_OneVariable.html",
    "href": "02_OneVariable.html",
    "title": "2  Looking for Patterns in One Variable",
    "section": "",
    "text": "Categorical\nWhat we’re looking for here are relative proportions. Does some categories stand out from the others? We’ve seen the geom_bar geometry be used for this. But what if the counts are already in the data? For example, look at the HairEyeColor dataset from the modeldata package:\nhairEye&lt;-as_tibble(HairEyeColor)\nhairEye\n\n# A tibble: 32 × 4\n   Hair  Eye   Sex       n\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n 1 Black Brown Male     32\n 2 Brown Brown Male     53\n 3 Red   Brown Male     10\n 4 Blond Brown Male      3\n 5 Black Blue  Male     11\n 6 Brown Blue  Male     50\n 7 Red   Blue  Male     10\n 8 Blond Blue  Male     30\n 9 Black Hazel Male     10\n10 Brown Hazel Male     25\n# ℹ 22 more rows\nThis is data on hair and eye color recorded in a statistics class. Here, we can see columns giving the categories of hair and eye color, as well as sex, while the counts for each combination are stored in the n variable (shorthand for number). Normally, the geom_bar function counts each instance for us, so if we use that here, it will just count each time a category is mentioned in that column:\nggplot(data=hairEye,aes(x=Hair)) + \n  geom_bar()\nThis is technically a correct use of a bar plot, but since the number of people is actually stored as a separate variable, the number of instances of each category is the same, so the output is not especially helpful. There are a few different ways we can deal with this, but one way is to use the geom_col function:\nggplot(data=hairEye,aes(x=Hair,y=n)) + \n  geom_col()\nThis function makes two aesthetic mappings: the variable of interest on the x-axis (in this case, Hair), and the sum of the number of instances as a column-stored variable (n) on the y-axis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Looking for Patterns in One Variable</span>"
    ]
  },
  {
    "objectID": "02_OneVariable.html#footnotes",
    "href": "02_OneVariable.html#footnotes",
    "title": "2  Looking for Patterns in One Variable",
    "section": "",
    "text": "This is known as the ecological fallacy. Think of it this way: if I know that the average household income in Neighborhood A is lower than Neighborhood B, I cannot then use that information to say that the income of a household in Neighborhood A is less than that of one in Neighborhood B. In fact, the reverse could easily be true.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Looking for Patterns in One Variable</span>"
    ]
  },
  {
    "objectID": "03_TwoPlusVariables.html",
    "href": "03_TwoPlusVariables.html",
    "title": "3  Looking for Patterns in More than One Variable",
    "section": "",
    "text": "Categorical and numerical variables\nLike histograms, boxplots show the center, spread, and shape of distributions, but these are most useful when comparing more than one group. These usually have four main components:\nHave a look at the Sacramento dataset from the modeldata package:\n#library(modeldata)\nSacramento\n\n# A tibble: 932 × 9\n   city           zip     beds baths  sqft type        price latitude longitude\n   &lt;fct&gt;          &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;       &lt;int&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 SACRAMENTO     z95838     2     1   836 Residential 59222     38.6     -121.\n 2 SACRAMENTO     z95823     3     1  1167 Residential 68212     38.5     -121.\n 3 SACRAMENTO     z95815     2     1   796 Residential 68880     38.6     -121.\n 4 SACRAMENTO     z95815     2     1   852 Residential 69307     38.6     -121.\n 5 SACRAMENTO     z95824     2     1   797 Residential 81900     38.5     -121.\n 6 SACRAMENTO     z95841     3     1  1122 Condo       89921     38.7     -121.\n 7 SACRAMENTO     z95842     3     2  1104 Residential 90895     38.7     -121.\n 8 SACRAMENTO     z95820     3     1  1177 Residential 91002     38.5     -121.\n 9 RANCHO_CORDOVA z95670     2     2   941 Condo       94905     38.6     -121.\n10 RIO_LINDA      z95673     3     2  1146 Residential 98937     38.7     -121.\n# ℹ 922 more rows\nLots of variables to look at here, including nominal (city, type), interval (latitude, longitude), and ratio (beds, sqft, price). To get a quick sense of what things are looking like, we can use a boxplot to examine the relationship between a nominal variable (type) and a ratio variable (price):\nggplot(data=Sacramento,aes(x=type,y=price)) +   \n  geom_boxplot()\nFirst, there’s a good deal of overlap between these different categories. However, the mean values are greater for multifamily and residential-type housing than they are for condominiums. Finally, there are a fair number of of outliers in the residential-type, indicating a positive skew in the data. We’ll come back to this a bit later. By viewing these boxplots side-by-side, we’re turning our univariate view of price into a bivariate view by type.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Looking for Patterns in More than One Variable</span>"
    ]
  },
  {
    "objectID": "03_TwoPlusVariables.html#footnotes",
    "href": "03_TwoPlusVariables.html#footnotes",
    "title": "3  Looking for Patterns in More than One Variable",
    "section": "",
    "text": "The r used here actually comes from the term reversion, which was a term the mathematician Francis Galton used for the operation we now call regression. This is something we will talk about in a later lecture.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Looking for Patterns in More than One Variable</span>"
    ]
  },
  {
    "objectID": "04_WhenThingsLookWeird.html",
    "href": "04_WhenThingsLookWeird.html",
    "title": "4  What To Do With Outliers",
    "section": "",
    "text": "So far, most of the example data we have dealt have been selected because they fit the purpose of demonstrating a concept. But real data seldom comes without some kind of issue, problem, or weirdness. People constantly make data entry mistakes, data collection and storage protocols are rarely standardized, and data often include cases that, real or not, fly in the face of our expectations.\nConducting EDA means keeping a critical eye out for these kinds of things, and being able to make judgement calls about when a value is an appropriate outlier and when it is truly weird. In this section, we’ll look at how we deal with this.\n\nOutliers and unusual values\nAs we mentioned in our discussion of visualizing categorical and numerical data using boxplots, outliers are indicated using points:\n\nggplot(data=Sacramento,aes(x=type,y=price)) +   \n  geom_boxplot()\n\n\n\n\n\n\n\n\nWhen we see these outliers, our first question should be: do these values make sense? Besides the house prices being shockingly out-of-date (the median house price in Sacamento is closer to $470,000 now), having home prices in the vicinity of $750,000 doesn’t seem wildly out of character. And if we do some digging on house prices, we know that house prices are often positively skewed, with some prices being substantially higher than the average:\n\n\n\nhttps://www.urban.org/urban-wire/bostons-housing-market-three-charts\n\n\nSo while houseprices are generally crazy to think about, these outliers don’t seem completely outrageuos and probably reflect what we would expect for this type of distribution. Let’s look at something a bit less reasonable:\n\nggplot(data=abalone,aes(x=height*200,y=weight.shucked*200)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x=\"Height (mm)\",y=\"Length (mm)\")\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nIs it real? Does it make sense? How can we tell? To do this, we’ll have to think a little critically about what our data represent: the dimensions of shellfish. Abalone are bivalves that are shaped more or less like oblong discs, so their height isn’t typyically greater than their length. We can plot height by length to see if this is generally true for our data:\n\nggplot(data=abalone,aes(x=height*200,y=length*200)) +\n  geom_point() +\n  labs(x=\"Height (mm)\",y=\"Length (mm)\")\n\n\n\n\n\n\n\n\nWe can see most of our data falls on the left and are our outliers on the right hand side. For the tallest one, which has a height somewhere around 225 mm, it is only showing a length of around 90 mm. This means that this abalone is taller than it is wide, which would make for a very strange looking shellfish.\nWhat might explain this? It seems possible that the person recording the data made a mistake. Looking at the data, we can see that most other abalones recorded in this dataset with a length of around 90 mm have a height of about 25 mm. It’s entirely possible that whoever entered this data added an extra 2 when typing it in.\nUnfortunately, it’s not good practice to second-guess what someone meant to enter. It could have been 25, or 22, or something else that they meant to type all together. So rather than change the data to a value with think is correct, the safer thing to do is to eliminate that observation. We can use the square brackets to do this:\n\nabalone2&lt;-abalone[abalone$height*200&lt;150,]\nggplot(data=abalone2,aes(x=height*200,y=weight.shucked*200)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x=\"Height (mm)\",y=\"Length (mm)\")\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\nHowever, when you start removing data it is EXTREMELY important that you document that you are doing so, and explain why. Comments in your script are a good place to do this.\n\n#Removing outlier due to suspect height value (too high for length)\nabalone2&lt;-abalone[abalone$height*200&lt;150,]\n\nggplot(data=abalone2,aes(x=height*200,y=weight.shucked*200)) +\n  geom_point() +\n  geom_smooth() +\n  labs(x=\"Height (mm)\",y=\"Length (mm)\")\n\n`geom_smooth()` using method = 'gam' and formula = 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTry it yourself!\n\n\n\nTake a good look at that other outlier in the heights (on the far right of the last plot). Does it make sense? Why or why not?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>What To Do With Outliers</span>"
    ]
  },
  {
    "objectID": "06_LabExercise4.html",
    "href": "06_LabExercise4.html",
    "title": "5  Lab Exercise 4",
    "section": "",
    "text": "Public Domain, https://commons.wikimedia.org/w/index.php?curid=205407\n\n\nIn 2012, a researcher in coastal California was looking for ways to better assess populations of larger mammalian predators for conservation purposes. Their solution? To determine how effectively morphometric traits (shape and size measurements) from animal dung could be used to distinguish particular species. To do this, they collected samples and identified the species using DNA, and then conducted a series of measurements on each sample like length and diameter, as well as shape characteristics such as tapering and segmentation.\nYour academic supervisor came across this dataset and wants to know what sorts of things you would look for in this data before you both go off to spend the summer in the woods collecting animal scat. Like a good data scientist, you’re going to do a bit of EDA to take a look at the data first.\nUsing the predatorScat.csv data file, produce a script that demonstrates how you would look at this data. In particular, I want you to be able to show do the following:\n\nLook at 2 different kinds of data in a univariate analysis, and describe the kinds of patterning you see (hint: be careful that numbers are not representing categories!)\nLook at 2 different kinds of relationships in a bivariate analysis (e.g., two numerical, two categorical, numerical-categorical), and describe the patterning you see\nChoose numerical summaries metrics to look at central tendency and spread of one of the numerical variables\nIdentify any outliers in the data and whether they appear to be genuine or suspect\n\nWrite your findings as comments in the script alongside the code used to produce the graph and submit the script on Canvas.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Lab Exercise 4</span>"
    ]
  }
]